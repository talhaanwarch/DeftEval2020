{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of deftEval_GloVe-GRU",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ4QJP-XYRps",
        "colab_type": "code",
        "outputId": "6c0264b3-1cba-4ed7-bf47-d93b71840873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "!pip install keras_metrics\n",
        "!pip install extra-keras-metrics\n",
        "!pip install keras-self-attention"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_metrics in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.6/dist-packages (from keras_metrics) (2.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.17.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.3.1)\n",
            "Requirement already satisfied: extra-keras-metrics in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from extra-keras-metrics) (2.2.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from extra-keras-metrics) (4.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->extra-keras-metrics) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->extra-keras-metrics) (1.17.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->extra-keras-metrics) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->extra-keras-metrics) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->extra-keras-metrics) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->extra-keras-metrics) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->extra-keras-metrics) (1.3.1)\n",
            "Requirement already satisfied: keras-self-attention in /usr/local/lib/python3.6/dist-packages (0.42.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (1.17.3)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (2.2.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (2.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-6UvuYsYnEJ",
        "colab_type": "code",
        "outputId": "c68dd2b8-c5fc-482e-bcfb-5b79c7068146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import keras_metrics as km\n",
        "import extra_keras_metrics as ekm\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgPHqUe8EPRa",
        "colab_type": "code",
        "outputId": "04ef1485-3330-4b96-ab50-a4eb0a7d169b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTD5-JmVEUHL",
        "colab_type": "code",
        "outputId": "bf755232-292b-45ce-fe93-6bc4dce40eb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/dataset/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow_fcOEPEhad",
        "colab_type": "code",
        "outputId": "6693a102-91e1-424f-9c31-ca85cc402048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdeft_eval\u001b[0m/  \u001b[01;34mEEG\u001b[0m/  images.zip  \u001b[01;34mOLID\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na4-p1JCELdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import string\n",
        "import re\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ajqEqUUE5Fx",
        "colab_type": "code",
        "outputId": "fa5be296-a9da-4ef2-ceb2-77616736f52e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words(\"english\")) \n",
        "lemmatizer = WordNetLemmatizer()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcFkqtraEQLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_files = glob.glob('deft_eval/train/' + \"*.deft\")\n",
        "li = []\n",
        "for filename in train_files:\n",
        "    df = pd.read_csv(filename, sep='\\t',index_col=None, header=None,names=['sentence','label'])\n",
        "    li.append(df)\n",
        "\n",
        "frame = pd.concat(li, axis=0, ignore_index=True)\n",
        "y_train=frame['label']\n",
        "corpus_train = []\n",
        "for j in frame['sentence']:\n",
        "    df=j.lower()\n",
        "    df=df.translate(str.maketrans('', '', string.punctuation))\n",
        "    df=df.replace( 'link ','')\n",
        "    df=''.join([i for i in df if not i.isdigit()]) \n",
        "    df=\" \".join(df.split())\n",
        "    df = [lemmatizer.lemmatize(token) for token in df.split(\" \")]\n",
        "    df=[word for word in df if not word in stop_words]\n",
        "    df=\" \".join(df)\n",
        "    corpus_train.append(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hx272yuBFew0",
        "colab_type": "code",
        "outputId": "02e627aa-3198-485b-8853-e13c30a7c5a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "len(corpus_train),corpus_train[0],y_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16659,\n",
              " 'science includes diverse field astronomy biology computer science geology logic physic chemistry mathematics',\n",
              " 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dvF59TxEztB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev_files = glob.glob('deft_eval/dev/' + \"*.deft\")\n",
        "li = []\n",
        "for filename in dev_files:\n",
        "    df = pd.read_csv(filename, sep='\\t',index_col=None, header=None,names=['sentence','label'])\n",
        "    li.append(df)\n",
        "\n",
        "frame = pd.concat(li, axis=0, ignore_index=True)\n",
        "y_dev=frame['label']\n",
        "corpus_dev = []\n",
        "for j in frame['sentence']:\n",
        "    df=j.lower()\n",
        "    df=df.translate(str.maketrans('', '', string.punctuation))\n",
        "    df=df.replace( 'link ','')\n",
        "    df=''.join([i for i in df if not i.isdigit()]) \n",
        "    df=\" \".join(df.split())\n",
        "    df = [lemmatizer.lemmatize(token) for token in df.split(\" \")]\n",
        "    df=[word for word in df if not word in stop_words]\n",
        "    df=\" \".join(df)\n",
        "    corpus_dev.append(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyvrnPA-Fozr",
        "colab_type": "code",
        "outputId": "67a19fa4-3999-4be7-b6b1-377209f7e97b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "len(corpus_dev),corpus_dev[0],y_dev[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(810,\n",
              " 'becomes clear definition application scientific method play major role science',\n",
              " 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TadFtX9hY2jz",
        "colab_type": "code",
        "outputId": "c4de6619-4d4b-40a8-fc13-c5c15d0050b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import collections\n",
        "collections.Counter(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 11090, 1: 5569})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7xwg4b-EvUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "max_words = 10000 #frequency of words to be kept\n",
        "max_len = 300\n",
        "tokenize = Tokenizer(num_words=max_words)\n",
        "tokenize.fit_on_texts(corpus_train)\n",
        "sequences = tokenize.texts_to_sequences(corpus_train)\n",
        "X_train = sequence.pad_sequences(sequences,maxlen=max_len)\n",
        "word_index = tokenize.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYnUCAjYAOOd",
        "colab_type": "code",
        "outputId": "ec705b8b-084d-48bb-f432-17a9f0e5d946",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "embeddings_index = {}\n",
        "f = open('OLID/glove.6B.100d.txt',encoding='utf8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwjJEiynAQbN",
        "colab_type": "code",
        "outputId": "cb972dda-16c0-41c7-c18f-f8af88cc9998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_words = min(max_words, len(word_index)) + 1\n",
        "print(num_words)\n",
        "\n",
        "embedding_dim = 100\n",
        "\n",
        "# first create a matrix of zeros, this is our embedding matrix\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "\n",
        "# for each word in out tokenizer lets try to find that work in our w2v model\n",
        "for word, i in word_index.items():\n",
        "    if i > max_words:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # we found the word - add that words vector to the matrix\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        # doesn't exist, assign a random vector\n",
        "        embedding_matrix[i] = np.random.randn(embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MCP9ljoZKpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sequences = tokenize.texts_to_sequences(corpus_dev)\n",
        "X_dev = sequence.pad_sequences(test_sequences,maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB8qW7jFGQlj",
        "colab_type": "code",
        "outputId": "3b932017-aed2-4a72-e025-6ca78a89a602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding,CuDNNGRU,Dense,Dropout,Bidirectional,SpatialDropout1D,GlobalMaxPool1D\n",
        "from keras.optimizers import RMSprop,Adam\n",
        "from sklearn.utils import class_weight\n",
        "from keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "import keras_metrics as km\n",
        "from keras_self_attention import SeqSelfAttention\n",
        "\n",
        "\n",
        "from keras.initializers import Constant\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(num_words,\n",
        "                    embedding_dim,\n",
        "                    embeddings_initializer=Constant(embedding_matrix),\n",
        "                    input_length=max_len,\n",
        "                    trainable=True))\n",
        "\n",
        "model.add((CuDNNGRU(30,return_sequences=True)))\n",
        "model.add(SeqSelfAttention(attention_width=20,attention_activation='relu',attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL))\n",
        "\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(30, activation=\"sigmoid\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(0.0001), metrics=[km.binary_f1_score()])\n",
        "\n",
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)\n",
        "class_weights=dict(enumerate(class_weights))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 300, 100)          1000100   \n",
            "_________________________________________________________________\n",
            "cu_dnngru_1 (CuDNNGRU)       (None, 300, 30)           11880     \n",
            "_________________________________________________________________\n",
            "seq_self_attention_1 (SeqSel (None, 300, 30)           901       \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 30)                930       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 1,013,842\n",
            "Trainable params: 1,013,842\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG-PhyfzZIA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_f1_score', mode='max', min_delta=0,patience=5,restore_best_weights=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-FFhG0iGYvL",
        "colab_type": "code",
        "outputId": "49002c4b-aee6-48cb-81b1-94bad1cbf2ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train,y_train,batch_size=30,epochs=50,verbose=2,class_weight=class_weights,validation_data=(X_dev,y_dev),callbacks=[es])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 16659 samples, validate on 810 samples\n",
            "Epoch 1/50\n",
            " - 31s - loss: 0.7444 - f1_score: 0.4098 - val_loss: 0.6901 - val_f1_score: 0.5215\n",
            "Epoch 2/50\n",
            " - 29s - loss: 0.7133 - f1_score: 0.4360 - val_loss: 0.6668 - val_f1_score: 0.5402\n",
            "Epoch 3/50\n",
            " - 29s - loss: 0.6749 - f1_score: 0.4902 - val_loss: 0.6278 - val_f1_score: 0.5728\n",
            "Epoch 4/50\n",
            " - 28s - loss: 0.6364 - f1_score: 0.5500 - val_loss: 0.5944 - val_f1_score: 0.5867\n",
            "Epoch 5/50\n",
            " - 28s - loss: 0.6098 - f1_score: 0.5942 - val_loss: 0.5753 - val_f1_score: 0.6149\n",
            "Epoch 6/50\n",
            " - 28s - loss: 0.5886 - f1_score: 0.6211 - val_loss: 0.5721 - val_f1_score: 0.6168\n",
            "Epoch 7/50\n",
            " - 28s - loss: 0.5681 - f1_score: 0.6392 - val_loss: 0.5539 - val_f1_score: 0.6185\n",
            "Epoch 8/50\n",
            " - 28s - loss: 0.5547 - f1_score: 0.6468 - val_loss: 0.5468 - val_f1_score: 0.6103\n",
            "Epoch 9/50\n",
            " - 28s - loss: 0.5375 - f1_score: 0.6661 - val_loss: 0.5412 - val_f1_score: 0.6221\n",
            "Epoch 10/50\n",
            " - 28s - loss: 0.5199 - f1_score: 0.6791 - val_loss: 0.5354 - val_f1_score: 0.6285\n",
            "Epoch 11/50\n",
            " - 28s - loss: 0.5082 - f1_score: 0.6945 - val_loss: 0.5311 - val_f1_score: 0.6451\n",
            "Epoch 12/50\n",
            " - 28s - loss: 0.4920 - f1_score: 0.7056 - val_loss: 0.5238 - val_f1_score: 0.6434\n",
            "Epoch 13/50\n",
            " - 28s - loss: 0.4801 - f1_score: 0.7174 - val_loss: 0.5228 - val_f1_score: 0.6541\n",
            "Epoch 14/50\n",
            " - 28s - loss: 0.4654 - f1_score: 0.7299 - val_loss: 0.5112 - val_f1_score: 0.6634\n",
            "Epoch 15/50\n",
            " - 28s - loss: 0.4504 - f1_score: 0.7437 - val_loss: 0.5083 - val_f1_score: 0.6733\n",
            "Epoch 16/50\n",
            " - 28s - loss: 0.4344 - f1_score: 0.7552 - val_loss: 0.5108 - val_f1_score: 0.6755\n",
            "Epoch 17/50\n",
            " - 28s - loss: 0.4252 - f1_score: 0.7634 - val_loss: 0.5239 - val_f1_score: 0.6795\n",
            "Epoch 18/50\n",
            " - 28s - loss: 0.4110 - f1_score: 0.7749 - val_loss: 0.5177 - val_f1_score: 0.6810\n",
            "Epoch 19/50\n",
            " - 28s - loss: 0.3971 - f1_score: 0.7845 - val_loss: 0.5325 - val_f1_score: 0.6849\n",
            "Epoch 20/50\n",
            " - 28s - loss: 0.3829 - f1_score: 0.7920 - val_loss: 0.5252 - val_f1_score: 0.6802\n",
            "Epoch 21/50\n",
            " - 28s - loss: 0.3712 - f1_score: 0.7993 - val_loss: 0.5294 - val_f1_score: 0.6849\n",
            "Epoch 22/50\n",
            " - 28s - loss: 0.3624 - f1_score: 0.8108 - val_loss: 0.5443 - val_f1_score: 0.6856\n",
            "Epoch 23/50\n",
            " - 28s - loss: 0.3481 - f1_score: 0.8183 - val_loss: 0.5558 - val_f1_score: 0.6843\n",
            "Epoch 24/50\n",
            " - 28s - loss: 0.3378 - f1_score: 0.8268 - val_loss: 0.5636 - val_f1_score: 0.6868\n",
            "Epoch 25/50\n",
            " - 28s - loss: 0.3277 - f1_score: 0.8367 - val_loss: 0.5696 - val_f1_score: 0.6825\n",
            "Epoch 26/50\n",
            " - 28s - loss: 0.3143 - f1_score: 0.8413 - val_loss: 0.5877 - val_f1_score: 0.6898\n",
            "Epoch 27/50\n",
            " - 28s - loss: 0.3039 - f1_score: 0.8486 - val_loss: 0.5982 - val_f1_score: 0.6811\n",
            "Epoch 28/50\n",
            " - 28s - loss: 0.2926 - f1_score: 0.8554 - val_loss: 0.6043 - val_f1_score: 0.6890\n",
            "Epoch 29/50\n",
            " - 28s - loss: 0.2850 - f1_score: 0.8627 - val_loss: 0.6057 - val_f1_score: 0.6861\n",
            "Epoch 30/50\n",
            " - 28s - loss: 0.2805 - f1_score: 0.8672 - val_loss: 0.6244 - val_f1_score: 0.6942\n",
            "Epoch 31/50\n",
            " - 28s - loss: 0.2673 - f1_score: 0.8723 - val_loss: 0.6292 - val_f1_score: 0.6783\n",
            "Epoch 32/50\n",
            " - 28s - loss: 0.2573 - f1_score: 0.8785 - val_loss: 0.6402 - val_f1_score: 0.6827\n",
            "Epoch 33/50\n",
            " - 28s - loss: 0.2512 - f1_score: 0.8828 - val_loss: 0.6561 - val_f1_score: 0.6913\n",
            "Epoch 34/50\n",
            " - 28s - loss: 0.2448 - f1_score: 0.8864 - val_loss: 0.6720 - val_f1_score: 0.6778\n",
            "Epoch 35/50\n",
            " - 28s - loss: 0.2345 - f1_score: 0.8924 - val_loss: 0.6722 - val_f1_score: 0.6713\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f84466a8c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QJVrux7X_HK",
        "colab_type": "code",
        "outputId": "face4db3-f1d1-4911-b3dc-143c53b7c81d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "\n",
        "print(model.evaluate(X_dev,y_dev))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "810/810 [==============================] - 0s 588us/step\n",
            "[0.6243823968333962, 0.6942148262790828]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A__4QcfbEbfj",
        "colab_type": "code",
        "outputId": "0a2220fd-94ce-4da6-a612-c506870a4d3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict(X_dev, batch_size=30, verbose=1)\n",
        "\n",
        "print(classification_report(y_dev, y_pred.round()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "810/810 [==============================] - 1s 655us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.77      0.82       537\n",
            "           1       0.63      0.77      0.69       273\n",
            "\n",
            "    accuracy                           0.77       810\n",
            "   macro avg       0.75      0.77      0.76       810\n",
            "weighted avg       0.79      0.77      0.78       810\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytyZj9MoD1VD",
        "colab_type": "code",
        "outputId": "31e0b852-5cbe-4433-d0c1-e193c7306102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(y_dev,y_pred.round())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[415, 122],\n",
              "       [ 63, 210]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1muzKvLY8IV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ-D5Tf2YQXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZiTzteAqwAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
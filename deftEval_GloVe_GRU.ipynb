{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deftEval_GloVe-GRU",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talhaanwarch/DeftEval2020/blob/master/deftEval_GloVe_GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgPHqUe8EPRa",
        "colab_type": "code",
        "outputId": "23318c40-91cc-4ab0-e465-8aa1d5f47ae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTD5-JmVEUHL",
        "colab_type": "code",
        "outputId": "9d580d33-2ee9-4a99-8efd-cfd5e81e62a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/dataset/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow_fcOEPEhad",
        "colab_type": "code",
        "outputId": "397a3ee2-a9af-46fb-988b-95f3ce9fab3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdeft_eval\u001b[0m/  \u001b[01;34mEEG\u001b[0m/  images.zip  \u001b[01;34mOLID\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na4-p1JCELdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import string\n",
        "import re\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ajqEqUUE5Fx",
        "colab_type": "code",
        "outputId": "807f80c0-2599-4e51-9065-cfa024fd7edb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words(\"english\")) \n",
        "lemmatizer = WordNetLemmatizer()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcFkqtraEQLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_files = glob.glob('deft_eval/train/' + \"*.deft\")\n",
        "li = []\n",
        "for filename in train_files:\n",
        "    df = pd.read_csv(filename, sep='\\t',index_col=None, header=None,names=['sentence','label'])\n",
        "    li.append(df)\n",
        "\n",
        "frame = pd.concat(li, axis=0, ignore_index=True)\n",
        "y_train=frame['label']\n",
        "corpus_train = []\n",
        "for j in frame['sentence']:\n",
        "    df=j.lower()\n",
        "    df=df.translate(str.maketrans('', '', string.punctuation))\n",
        "    df=df.replace( 'link ','')\n",
        "    df=''.join([i for i in df if not i.isdigit()]) \n",
        "    df=\" \".join(df.split())\n",
        "    df = [lemmatizer.lemmatize(token) for token in df.split(\" \")]\n",
        "    df=[word for word in df if not word in stop_words]\n",
        "    df=\" \".join(df)\n",
        "    corpus_train.append(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hx272yuBFew0",
        "colab_type": "code",
        "outputId": "7478a235-6f49-4767-af3c-2442a0fda613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "len(corpus_train),corpus_train[0],y_train[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16659,\n",
              " 'science includes diverse field astronomy biology computer science geology logic physic chemistry mathematics',\n",
              " 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dvF59TxEztB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev_files = glob.glob('deft_eval/dev/' + \"*.deft\")\n",
        "li = []\n",
        "for filename in dev_files:\n",
        "    df = pd.read_csv(filename, sep='\\t',index_col=None, header=None,names=['sentence','label'])\n",
        "    li.append(df)\n",
        "\n",
        "frame = pd.concat(li, axis=0, ignore_index=True)\n",
        "y_dev=frame['label']\n",
        "corpus_dev = []\n",
        "for j in frame['sentence']:\n",
        "    df=j.lower()\n",
        "    df=df.translate(str.maketrans('', '', string.punctuation))\n",
        "    df=df.replace( 'link ','')\n",
        "    df=''.join([i for i in df if not i.isdigit()]) \n",
        "    df=\" \".join(df.split())\n",
        "    df = [lemmatizer.lemmatize(token) for token in df.split(\" \")]\n",
        "    df=[word for word in df if not word in stop_words]\n",
        "    df=\" \".join(df)\n",
        "    corpus_dev.append(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyvrnPA-Fozr",
        "colab_type": "code",
        "outputId": "48af8ccf-45ee-4068-c536-1e0bb1c992bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "len(corpus_dev),corpus_dev[0],y_dev[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(810,\n",
              " 'becomes clear definition application scientific method play major role science',\n",
              " 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TadFtX9hY2jz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a2f57b9-d644-47d8-973c-0cd4d2e9cecc"
      },
      "source": [
        "import collections\n",
        "collections.Counter(y_train)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 11090, 1: 5569})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7xwg4b-EvUX",
        "colab_type": "code",
        "outputId": "e86102c6-b632-43f6-dd9c-27e9e318c844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "max_words = 10000 #frequency of words to be kept\n",
        "max_len = 300\n",
        "tokenize = Tokenizer(num_words=max_words)\n",
        "tokenize.fit_on_texts(corpus_train)\n",
        "sequences = tokenize.texts_to_sequences(corpus_train)\n",
        "X_train = sequence.pad_sequences(sequences,maxlen=max_len)\n",
        "word_index = tokenize.word_index"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYnUCAjYAOOd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75b3f7a7-d176-41c8-a0b7-36f7446a24e1"
      },
      "source": [
        "import os\n",
        "embeddings_index = {}\n",
        "f = open('OLID/glove.6B.100d.txt',encoding='utf8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwjJEiynAQbN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa30af55-445b-47ec-b74c-efd579b3dcdd"
      },
      "source": [
        "num_words = min(max_words, len(word_index)) + 1\n",
        "print(num_words)\n",
        "\n",
        "embedding_dim = 100\n",
        "\n",
        "# first create a matrix of zeros, this is our embedding matrix\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "\n",
        "# for each word in out tokenizer lets try to find that work in our w2v model\n",
        "for word, i in word_index.items():\n",
        "    if i > max_words:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # we found the word - add that words vector to the matrix\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        # doesn't exist, assign a random vector\n",
        "        embedding_matrix[i] = np.random.randn(embedding_dim)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MCP9ljoZKpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sequences = tokenize.texts_to_sequences(corpus_dev)\n",
        "X_dev = sequence.pad_sequences(test_sequences,maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB8qW7jFGQlj",
        "colab_type": "code",
        "outputId": "0fce638c-51b2-4a55-898c-7cf1afa1e310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding,CuDNNGRU,Dense,Dropout,Bidirectional,SpatialDropout1D,GlobalMaxPool1D\n",
        "from keras.optimizers import RMSprop,Adam\n",
        "from sklearn.utils import class_weight\n",
        "from keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "from keras.initializers import Constant\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(num_words,\n",
        "                    embedding_dim,\n",
        "                    embeddings_initializer=Constant(embedding_matrix),\n",
        "                    input_length=max_len,\n",
        "                    trainable=True))\n",
        "model.add( SpatialDropout1D(0.2))\n",
        "model.add((CuDNNGRU(50, return_sequences = True)))\n",
        "model.add(GlobalMaxPool1D())\n",
        "#model.add(Dense(80, activation=\"sigmoid\"))\n",
        "model.add(Dense(30, activation=\"sigmoid\"))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(0.0001), metrics=['accuracy'])\n",
        "\n",
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)\n",
        "class_weights=dict(enumerate(class_weights))\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 300, 100)          500100    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 300, 100)          0         \n",
            "_________________________________________________________________\n",
            "cu_dnngru_1 (CuDNNGRU)       (None, 300, 50)           22800     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 30)                1530      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 524,461\n",
            "Trainable params: 524,461\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG-PhyfzZIA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', min_delta=0,patience=5,restore_best_weights=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-FFhG0iGYvL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dca28078-e31d-4606-d9bd-58c58ac79ec3"
      },
      "source": [
        "model.fit(X_train,y_train,batch_size=30,epochs=50,verbose=2,class_weight=class_weights,validation_data=(X_dev,y_dev),callbacks=[es])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 16659 samples, validate on 810 samples\n",
            "Epoch 1/50\n",
            " - 32s - loss: 0.7154 - acc: 0.5569 - val_loss: 0.6623 - val_acc: 0.6333\n",
            "Epoch 2/50\n",
            " - 31s - loss: 0.6759 - acc: 0.5749 - val_loss: 0.6365 - val_acc: 0.6420\n",
            "Epoch 3/50\n",
            " - 31s - loss: 0.6503 - acc: 0.6177 - val_loss: 0.6165 - val_acc: 0.6593\n",
            "Epoch 4/50\n",
            " - 31s - loss: 0.6331 - acc: 0.6388 - val_loss: 0.5837 - val_acc: 0.6963\n",
            "Epoch 5/50\n",
            " - 31s - loss: 0.6182 - acc: 0.6585 - val_loss: 0.5976 - val_acc: 0.6753\n",
            "Epoch 6/50\n",
            " - 31s - loss: 0.6051 - acc: 0.6716 - val_loss: 0.5755 - val_acc: 0.6840\n",
            "Epoch 7/50\n",
            " - 31s - loss: 0.5929 - acc: 0.6813 - val_loss: 0.5738 - val_acc: 0.6889\n",
            "Epoch 8/50\n",
            " - 31s - loss: 0.5866 - acc: 0.6864 - val_loss: 0.5482 - val_acc: 0.7173\n",
            "Epoch 9/50\n",
            " - 31s - loss: 0.5748 - acc: 0.6996 - val_loss: 0.5641 - val_acc: 0.6827\n",
            "Epoch 10/50\n",
            " - 31s - loss: 0.5657 - acc: 0.6991 - val_loss: 0.5329 - val_acc: 0.7235\n",
            "Epoch 11/50\n",
            " - 31s - loss: 0.5555 - acc: 0.7117 - val_loss: 0.5476 - val_acc: 0.7062\n",
            "Epoch 12/50\n",
            " - 31s - loss: 0.5509 - acc: 0.7132 - val_loss: 0.5262 - val_acc: 0.7247\n",
            "Epoch 13/50\n",
            " - 31s - loss: 0.5395 - acc: 0.7224 - val_loss: 0.5243 - val_acc: 0.7259\n",
            "Epoch 14/50\n",
            " - 30s - loss: 0.5318 - acc: 0.7283 - val_loss: 0.5237 - val_acc: 0.7272\n",
            "Epoch 15/50\n",
            " - 31s - loss: 0.5246 - acc: 0.7349 - val_loss: 0.5212 - val_acc: 0.7235\n",
            "Epoch 16/50\n",
            " - 31s - loss: 0.5208 - acc: 0.7375 - val_loss: 0.5257 - val_acc: 0.7259\n",
            "Epoch 17/50\n",
            " - 30s - loss: 0.5159 - acc: 0.7391 - val_loss: 0.5328 - val_acc: 0.7160\n",
            "Epoch 18/50\n",
            " - 31s - loss: 0.5066 - acc: 0.7478 - val_loss: 0.5139 - val_acc: 0.7296\n",
            "Epoch 19/50\n",
            " - 31s - loss: 0.4994 - acc: 0.7518 - val_loss: 0.5106 - val_acc: 0.7358\n",
            "Epoch 20/50\n",
            " - 31s - loss: 0.4907 - acc: 0.7564 - val_loss: 0.5285 - val_acc: 0.7185\n",
            "Epoch 21/50\n",
            " - 30s - loss: 0.4879 - acc: 0.7618 - val_loss: 0.5090 - val_acc: 0.7432\n",
            "Epoch 22/50\n",
            " - 30s - loss: 0.4863 - acc: 0.7608 - val_loss: 0.5128 - val_acc: 0.7395\n",
            "Epoch 23/50\n",
            " - 31s - loss: 0.4812 - acc: 0.7623 - val_loss: 0.5097 - val_acc: 0.7432\n",
            "Epoch 24/50\n",
            " - 31s - loss: 0.4747 - acc: 0.7706 - val_loss: 0.5083 - val_acc: 0.7457\n",
            "Epoch 25/50\n",
            " - 30s - loss: 0.4706 - acc: 0.7702 - val_loss: 0.4997 - val_acc: 0.7568\n",
            "Epoch 26/50\n",
            " - 30s - loss: 0.4615 - acc: 0.7789 - val_loss: 0.5030 - val_acc: 0.7531\n",
            "Epoch 27/50\n",
            " - 31s - loss: 0.4580 - acc: 0.7804 - val_loss: 0.5166 - val_acc: 0.7506\n",
            "Epoch 28/50\n",
            " - 31s - loss: 0.4560 - acc: 0.7795 - val_loss: 0.5046 - val_acc: 0.7580\n",
            "Epoch 29/50\n",
            " - 30s - loss: 0.4494 - acc: 0.7840 - val_loss: 0.5105 - val_acc: 0.7531\n",
            "Epoch 30/50\n",
            " - 31s - loss: 0.4437 - acc: 0.7892 - val_loss: 0.5129 - val_acc: 0.7531\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7a704eceb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QJVrux7X_HK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8e01b35c-e035-4e8d-e4ca-72db7cc49390"
      },
      "source": [
        "\n",
        "print(model.evaluate(X_dev,y_dev))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "810/810 [==============================] - 0s 597us/step\n",
            "[0.4997013892656491, 0.7567901231624462]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw_7KyuTYoVx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "02c77ee0-ebfa-4c72-9553-0f0e9042d49a"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict(X_dev, batch_size=30, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "print(classification_report(y_dev, y_pred))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "810/810 [==============================] - 1s 703us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.79      0.81       537\n",
            "           1       0.63      0.69      0.66       273\n",
            "\n",
            "    accuracy                           0.76       810\n",
            "   macro avg       0.73      0.74      0.73       810\n",
            "weighted avg       0.76      0.76      0.76       810\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1muzKvLY8IV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwIa9qjzc23d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZiTzteAqwAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}